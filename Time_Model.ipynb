{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3021cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "import string\n",
    "import re\n",
    "import datetime, time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.dates as md\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce43d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Setup\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b31e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = open(path, 'rt')\n",
    "    f.readline()\n",
    "\n",
    "    for l in f:\n",
    "        \n",
    "        if l.startswith(\"timestamp\"): \n",
    "            continue\n",
    "\n",
    "        try: \n",
    "            timestamp,company,level,title,totalyearlycompensation,location,yearsofexperience,yearsatcompany,tag,basesalary,stockgrantvalue,bonus,gender,otherdetails,cityid,dmaid,rowNumber,Masters_Degree,Bachelors_Degree,Doctorate_Degree,Highschool,Some_College,Race_Asian,Race_White,Race_Two_Or_More,Race_Black,Race_Hispanic,Race,Education = re.split(r',(?![ ])', l)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        yield timestamp,company,level,title,totalyearlycompensation,location,yearsofexperience,yearsatcompany,tag,basesalary,stockgrantvalue,bonus,gender,otherdetails,cityid,dmaid,rowNumber,Masters_Degree,Bachelors_Degree,Doctorate_Degree,Highschool,Some_College,Race_Asian,Race_White,Race_Two_Or_More,Race_Black,Race_Hispanic,Race,Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b152a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16fcaae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Parse data from dataset\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7748719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id , unixtime, company, level, title, total_comp, city, state, experience, tenure, tag, \n",
    "# salary, stock, bonus, city_id, dma_id, ms_deg, bs_deg, phd_deg, hs, college\n",
    "def parseSalaryRaw(salaryRaw):\n",
    "    salaryAllData = []\n",
    "\n",
    "    for entry in salaryRaw:\n",
    "\n",
    "        date, clocktime = entry[0].split(' ')\n",
    "        date = date.split('/')\n",
    "        clocktime = clocktime.split(':')\n",
    "        timestamp = datetime.datetime(int(date[2]), int(date[0]), int(date[1]), int(clocktime[0]), int(clocktime[1]), int(clocktime[2]))\n",
    "        timestamp = int(time.mktime(timestamp.timetuple()))\n",
    "\n",
    "\n",
    "        company = entry[1]\n",
    "        level = entry[2]\n",
    "        title = entry[3]\n",
    "\n",
    "        total_comp = int(float(entry[4]))\n",
    "\n",
    "        location = entry[5]\n",
    "        if location.count(',') == 2:\n",
    "            city, state, country = location.strip('\"').split(', ')\n",
    "        elif location.count(',') == 1:\n",
    "            city, state = location.strip('\"').split(', ')\n",
    "            country = 'USA'\n",
    "\n",
    "        experience = entry[6]\n",
    "        tenure = entry[7]\n",
    "\n",
    "        tag = entry[8]\n",
    "\n",
    "        salary = int(float(entry[9]))\n",
    "        if salary == 0:\n",
    "            continue\n",
    "\n",
    "        stock = int(float(entry[10]))\n",
    "        bonus = int(float(entry[11]))\n",
    "\n",
    "        g = entry[12]\n",
    "        gender = -1\n",
    "        if g == 'Female':\n",
    "            gender = 0\n",
    "        elif g == 'Male':\n",
    "            gender = 1\n",
    "        elif g == 'Other':\n",
    "            gender = 2\n",
    "\n",
    "        city_id = int(entry[14])\n",
    "\n",
    "        try: \n",
    "            dma_id = int(entry[15])\n",
    "        except:\n",
    "            dma_id = -1\n",
    "\n",
    "        id = int(entry[16])\n",
    "\n",
    "        ms_deg = int(entry[17])\n",
    "        bs_deg = int(entry[18])\n",
    "        phd_deg = int(entry[18])\n",
    "        hs = int(entry[19])\n",
    "        college = int(entry[20])\n",
    "\n",
    "        r = entry[27]\n",
    "        race = -1\n",
    "        if r == 'Asian':\n",
    "            race = 0\n",
    "        elif r == 'Black':\n",
    "            race = 1\n",
    "        elif r == 'Hispanic':\n",
    "            race = 2\n",
    "        elif r == 'Two Or More':\n",
    "            race = 3\n",
    "        elif r == 'White':\n",
    "            race = 4\n",
    "\n",
    "\n",
    "        salaryAllData.append({\n",
    "            'id': id,\n",
    "            'timestamp': timestamp,\n",
    "            'company': company,\n",
    "            'level': level,\n",
    "            'title': title,\n",
    "            'total_comp': total_comp,\n",
    "            'city': city,\n",
    "            'state': state,\n",
    "            'country': country,\n",
    "            'experience': experience,\n",
    "            'tenure': tenure,\n",
    "            'tag': tag,\n",
    "            'salary': salary,\n",
    "            'stock': stock,\n",
    "            'bonus': bonus,\n",
    "            'gender': gender,\n",
    "            'city_id': city_id,\n",
    "            'dma_id': dma_id,\n",
    "            'ms_deg': ms_deg,\n",
    "            'bs_deg': bs_deg,\n",
    "            'phd_deg': phd_deg,\n",
    "            'hs': hs,\n",
    "            'college': college,\n",
    "            'race': race,\n",
    "        })\n",
    "    return salaryAllData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad341800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reparse data from CSV so we don't mess up above data\n",
    "salaryRaw = []\n",
    "for l in readCSV(\"Levels_Fyi_Salary_Data.csv\"):\n",
    "    salaryRaw.append(l)\n",
    "\n",
    "salaryAllData = parseSalaryRaw(salaryRaw)\n",
    "salaryAllData[0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf37090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse raw data\n",
    "salaryAllData = parseSalaryRaw(salaryRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "263da96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47996, 47996\n",
      "6000, 6000\n",
      "6000, 6000\n",
      "76391, 83046, 33750\n"
     ]
    }
   ],
   "source": [
    "#####\n",
    "# Training, Validation, and Test sets\n",
    "#####\n",
    "\n",
    "# shuffle data\n",
    "shuffledAllData = sklearn.utils.shuffle(salaryAllData)\n",
    "shuffledAllData[0]['id']\n",
    "\n",
    "# create 80 / 10 / 10 : Train / Validation / Test sets\n",
    "X = shuffledAllData\n",
    "y = [d['salary'] for d in shuffledAllData]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = sklearn.model_selection.train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_valid, X_test, y_valid, y_test = sklearn.model_selection.train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)\n",
    "\n",
    "# Validate that sets were created with propper sizes\n",
    "print(str(len(X_train)) + \", \" + str(len(y_train)))\n",
    "print(str(len(X_valid)) + \", \" + str(len(y_valid)))\n",
    "print(str(len(X_test)) + \", \" + str(len(y_test)))\n",
    "\n",
    "# Validate all ids are different\n",
    "print(str(X_train[0]['id']) + \", \" + str(X_valid[0]['id']) + \", \" + str(X_test[0]['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ccafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Baselines\n",
    "#   1. Predict average salary in dataset\n",
    "#   2. Predict average salary for given Years of Experience\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca7b8083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average salary: 141817.4728727394\n"
     ]
    }
   ],
   "source": [
    "# Create some useful collections for these baseline\n",
    "\n",
    "# create YOE to Average Map based on training data\n",
    "# We create two dictionaries to track the total salary seen at each YOE\n",
    "salByExpMap = defaultdict(int)\n",
    "\n",
    "# And the number of salaries seen at that YOE\n",
    "entriesByExpMap = defaultdict(int)\n",
    "\n",
    "# For each entry increment the total sal and num entries at that YOE\n",
    "# (This could be done with a running avg technique but that is too much work to code)\n",
    "for x in X_train:\n",
    "    exp, sal = float(x['experience']), float(x['salary'])\n",
    "    exp = math.ceil(exp)\n",
    "    \n",
    "    total = 0\n",
    "    numEntries = 0\n",
    "    \n",
    "    if salByExpMap[exp]:\n",
    "        total = salByExpMap[exp]\n",
    "    if entriesByExpMap[exp]:\n",
    "        numEntries = entriesByExpMap[exp]\n",
    "    \n",
    "    total += sal\n",
    "    numEntries += 1\n",
    "    \n",
    "    salByExpMap[exp] = total\n",
    "    entriesByExpMap[exp] = numEntries\n",
    "    \n",
    "\n",
    "    \n",
    "# Calculate averages by YOE as well as total avg\n",
    "totalSal = 0\n",
    "totalCount = 0\n",
    "\n",
    "averageSalaryByYoeMap = defaultdict(int)\n",
    "for exp in entriesByExpMap:\n",
    "    avg = salByExpMap[exp] / entriesByExpMap[exp]\n",
    "    averageSalaryByYoeMap[exp] = avg\n",
    "    \n",
    "    totalSal += salByExpMap[exp]\n",
    "    totalCount += entriesByExpMap[exp]\n",
    "\n",
    "avgSal = totalSal / totalCount\n",
    "\n",
    "print(\"Average salary: \" + str(avgSal))\n",
    "\n",
    "\n",
    "def pred_baseline1(x):    \n",
    "    return avgSal\n",
    "    \n",
    "def pred_baseline2(x):    \n",
    "    exp = math.ceil(float(x['experience']))\n",
    "\n",
    "    if averageSalaryByYoeMap[exp]:\n",
    "        return averageSalaryByYoeMap[exp]\n",
    "    else:\n",
    "        return avgSal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "6d3f1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline1():\n",
    "    # Returns average salary in dataset\n",
    "    y_b1 = []\n",
    "    y_b1_pred = []\n",
    "    \n",
    "    avg_err = 0\n",
    "    avg_percent_err = 0\n",
    "    \n",
    "    for d in X_valid:\n",
    "        pred = pred_baseline1(d)\n",
    "        actual = d['salary']\n",
    "        \n",
    "        y_b1_pred.append(pred)\n",
    "        y_b1.append(actual)\n",
    "        \n",
    "        avg_err += abs(actual - pred)\n",
    "        avg_percent_err += abs(100 * ((pred - actual) / actual))\n",
    "        \n",
    "    mse = MSE(y_b1_pred, y_b1)\n",
    "    \n",
    "    avg_err = avg_err / len(X_valid)\n",
    "    avg_percent_err = avg_percent_err / len(X_valid)\n",
    "    \n",
    "    return mse, avg_err, avg_percent_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "b4e36a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3226865779.940545\n",
      "39228.80793670302\n",
      "45.890112992112925\n"
     ]
    }
   ],
   "source": [
    "mse_b1, avg_err_b1, avg_percent_err_b1 = baseline1()\n",
    "print(mse_b1)\n",
    "print(avg_err_b1)\n",
    "print(avg_percent_err_b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b11c5e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline2():\n",
    "    # Takes rounded YOE for each datapoint and predicts average salary for that YOE\n",
    "    # If there are no entries for that YOE, predict overall average\n",
    "    y_b1 = []\n",
    "    y_b1_pred = []\n",
    "    \n",
    "    avg_err = 0\n",
    "    avg_percent_err = 0\n",
    "    \n",
    "    for d in X_valid:\n",
    "        pred = pred_baseline2(d)\n",
    "        actual = d['salary']\n",
    "        \n",
    "        y_b1_pred.append(pred)\n",
    "        y_b1.append(actual)\n",
    "        \n",
    "        avg_err += abs(actual - pred)\n",
    "        avg_percent_err += abs(100 * ((pred - actual) / actual))\n",
    "        \n",
    "    mse = MSE(y_b1_pred, y_b1)\n",
    "    \n",
    "    avg_err = avg_err / len(X_valid)\n",
    "    avg_percent_err = avg_percent_err / len(X_valid)\n",
    "    \n",
    "    return mse, avg_err, avg_percent_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f53a1c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2653897798.2106194\n",
      "34915.2403546613\n",
      "40.5771376588154\n"
     ]
    }
   ],
   "source": [
    "mse_b2, avg_err_b2, avg_percent_err_b2 = baseline2()\n",
    "print(mse_b2)\n",
    "print(avg_err_b2)\n",
    "print(avg_percent_err_b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561cc12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad2cbdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Model\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5670f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Provide a description of your model:\n",
    "#      1. What model are you using\n",
    "#      2. What information are you trying to incorporate into your model\n",
    "#      3. How are you building your feature vector?\n",
    "#      4. What interesting pieces of information did you learn? (i.e. most influential words, popular cities, etc)\n",
    "#####\n",
    "\n",
    "# Write description in comments here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4344905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1e146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "b70443c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1496860407, 107000), (1497218037, 155000), (1497500545, 169000), (1497635041, 120000), (1497684194, 157000), (1498009799, 110000), (1498160271, 180000), (1498164926, 135000), (1498192788, 165000), (1498537545, 157000)]\n",
      "2021-08-17 08:28:57\n"
     ]
    }
   ],
   "source": [
    "combined = []\n",
    "for x,y in zip(X_train, y_train):\n",
    "    combined.append((x['timestamp'], y))\n",
    "\n",
    "combined.sort()\n",
    "print(combined[:10])\n",
    "d = combined[len(combined)-1][0]\n",
    "print(datetime.datetime.fromtimestamp(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b8266582",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_time = [d[0] for d in combined]\n",
    "y_train_time = [d[1] for d in combined]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f0f841ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1455000\n",
      "47996\n",
      "47996\n",
      "169000\n",
      "141817.4728727394\n"
     ]
    }
   ],
   "source": [
    "wSize = 10\n",
    "ySum = sum(y_train_time[:wSize])\n",
    "sliding = []\n",
    "\n",
    "print(ySum)\n",
    "\n",
    "sliding.append(avgSal)\n",
    "\n",
    "for i in range(1, wSize):\n",
    "\n",
    "    prev = y_train_time[i-1]\n",
    "    sliding.append(avgSal)\n",
    "\n",
    "for i in range(wSize,len(y_train_time)):\n",
    "    ySum += y_train_time[i] - y_train_time[i-wSize]\n",
    "    sliding.append(ySum*1.0/wSize)\n",
    "\n",
    "\n",
    "print(len(sliding))\n",
    "print(len(y_train_time))\n",
    "print(y_train_time[2])\n",
    "print(sliding[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c7b45839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141817.4728727394\n",
      "107000\n"
     ]
    }
   ],
   "source": [
    "print(sliding[0])\n",
    "print(y_train_time[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ba271706",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MSE(sliding, y_train_time)\n",
    "\n",
    "avg_err = 0\n",
    "avg_percent_err = 0\n",
    "\n",
    "mae = sklearn.metrics.mean_absolute_error(y_train_time, sliding)\n",
    "mape = 100*sklearn.metrics.mean_absolute_percentage_error(y_train_time, sliding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "3df97aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2729628482.5204024\n",
      "37655.46004780095\n",
      "43.35101220648099\n"
     ]
    }
   ],
   "source": [
    "print(mse)\n",
    "print(mae)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418fa18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "4583ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = linear_model.LinearRegression()\n",
    "\n",
    "X_train_time = [[t] for t in sliding]\n",
    "\n",
    "mod.fit(X_train_time, y_train_time)\n",
    "\n",
    "pred = mod.predict(X_train_time)\n",
    "\n",
    "mse = MSE(pred, y_train_time)\n",
    "mae = sklearn.metrics.mean_absolute_error(y_train_time, pred)\n",
    "mape = 100*sklearn.metrics.mean_absolute_percentage_error(y_train_time, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "4277ecfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3132403061.9176316\n",
      "39665.50381308346\n",
      "48.06534719228379\n"
     ]
    }
   ],
   "source": [
    "print(mse)\n",
    "print(mae)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f8d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "e4d093fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "minYear = 2017\n",
    "maxYear = 2021\n",
    "\n",
    "def feature_time(d):\n",
    "    \n",
    "    unix_time = d['timestamp']\n",
    "    date = datetime.datetime.fromtimestamp(unix_time)\n",
    "\n",
    "    year = date.year\n",
    "    month = date.month\n",
    "    day = date.day\n",
    "    hour = date.hour\n",
    "    minute = date.minute\n",
    "\n",
    "    one_hot_year = [0]*(maxYear-minYear)\n",
    "    y_index = year - minYear\n",
    "\n",
    "    if y_index != 0:\n",
    "        one_hot_year[y_index-1] = 1\n",
    "\n",
    "    one_hot_month = [0]*11\n",
    "    m_index = month - 1\n",
    "\n",
    "    if m_index != 0:\n",
    "        one_hot_month[m_index-1] = 1\n",
    "\n",
    "    one_hot_day = [0]*31\n",
    "    d_index = day - 1\n",
    "\n",
    "    if d_index != 0:\n",
    "        one_hot_day[d_index-1] = 1\n",
    "\n",
    "    one_hot_hour = [0]*23\n",
    "    h_index = hour - 1\n",
    "\n",
    "    if h_index != 0:\n",
    "        one_hot_hour[h_index-1] = 1\n",
    "\n",
    "    return \\\n",
    "        one_hot_year \\\n",
    "        + one_hot_month \\\n",
    "        + one_hot_day \\\n",
    "        + one_hot_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "ccd9648c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = linear_model.LinearRegression()\n",
    "\n",
    "# mod = linear_model.Ridge(0.5)\n",
    "\n",
    "X_train_time = [feature_time(d) for d in X_train]\n",
    "y_train_time = y_train[:]\n",
    "\n",
    "mod.fit(X_train_time, y_train_time)\n",
    "\n",
    "# pred = mod.predict(X_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "a810a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse = sklearn.metrics.mean_squared_error(y_train_time, pred)\n",
    "# mae = sklearn.metrics.mean_absolute_error(y_train_time, pred)\n",
    "# mape = 100*sklearn.metrics.mean_absolute_percentage_error(y_train_time, pred)\n",
    "\n",
    "# print(mse)\n",
    "# print(mae)\n",
    "# print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "3f3d1449",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_time = [feature_time(d) for d in X_valid]\n",
    "y_valid_time = y_valid[:]\n",
    "\n",
    "pred = mod.predict(X_valid_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "651ff9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3146043983.2483754\n",
      "39045.645395399115\n",
      "44.17728667869956\n"
     ]
    }
   ],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(y_valid_time, pred)\n",
    "mae = sklearn.metrics.mean_absolute_error(y_valid_time, pred)\n",
    "mape = 100*sklearn.metrics.mean_absolute_percentage_error(y_valid_time, pred)\n",
    "\n",
    "print(mse)\n",
    "print(mae)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "811d7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_time = [feature_time(d) for d in X_test]\n",
    "y_test_time = y_test[:]\n",
    "\n",
    "pred = mod.predict(X_test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "faec095c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3344115848.3050284\n",
      "39317.06383225119\n",
      "46.452416555328405\n"
     ]
    }
   ],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(y_test_time, pred)\n",
    "mae = sklearn.metrics.mean_absolute_error(y_test_time, pred)\n",
    "mape = 100*sklearn.metrics.mean_absolute_percentage_error(y_test_time, pred)\n",
    "\n",
    "print(mse)\n",
    "print(mae)\n",
    "print(mape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('cse158')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac74f00bb737bda1193c7532d1e44c439c6667b487a94e2d9bb09c77518a7e40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
